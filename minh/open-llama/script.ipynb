{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GenerationConfig, LlamaTokenizer, LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /mnt/home/lehoangminhtrinh/env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /mnt/home/lehoangminhtrinh/env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lehoangminhtrinh/env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda-10.1')}\n",
      "  warn(msg)\n",
      "/mnt/home/lehoangminhtrinh/env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/mnt/home/lehoangminhtrinh/env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/mnt/home/lehoangminhtrinh/env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer \u001b[39m=\u001b[39m LlamaTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mchainyo/alpaca-lora-7b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m LlamaForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mchainyo/alpaca-lora-7b\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     load_in_8bit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      5\u001b[0m     torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat16,\n\u001b[1;32m      6\u001b[0m     device_map\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m generation_config \u001b[39m=\u001b[39m GenerationConfig(\n\u001b[1;32m      9\u001b[0m     temperature\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[1;32m     10\u001b[0m     top_p\u001b[39m=\u001b[39m\u001b[39m0.75\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     max_new_tokens\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/env/lib/python3.8/site-packages/transformers/modeling_utils.py:2730\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2726\u001b[0m         device_map_without_lm_head \u001b[39m=\u001b[39m {\n\u001b[1;32m   2727\u001b[0m             key: device_map[key] \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m device_map\u001b[39m.\u001b[39mkeys() \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m modules_to_not_convert\n\u001b[1;32m   2728\u001b[0m         }\n\u001b[1;32m   2729\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m device_map_without_lm_head\u001b[39m.\u001b[39mvalues() \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdisk\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m device_map_without_lm_head\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m-> 2730\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2731\u001b[0m \u001b[39m                \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2732\u001b[0m \u001b[39m                Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\u001b[39;00m\n\u001b[1;32m   2733\u001b[0m \u001b[39m                the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\u001b[39;00m\n\u001b[1;32m   2734\u001b[0m \u001b[39m                these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\u001b[39;00m\n\u001b[1;32m   2735\u001b[0m \u001b[39m                `device_map` to `from_pretrained`. Check\u001b[39;00m\n\u001b[1;32m   2736\u001b[0m \u001b[39m                https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\u001b[39;00m\n\u001b[1;32m   2737\u001b[0m \u001b[39m                for more details.\u001b[39;00m\n\u001b[1;32m   2738\u001b[0m \u001b[39m                \"\"\"\u001b[39;00m\n\u001b[1;32m   2739\u001b[0m             )\n\u001b[1;32m   2740\u001b[0m         \u001b[39mdel\u001b[39;00m device_map_without_lm_head\n\u001b[1;32m   2742\u001b[0m \u001b[39mif\u001b[39;00m from_tf:\n",
      "\u001b[0;31mValueError\u001b[0m: \n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        "
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\"chainyo/alpaca-lora-7b\")\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    \"chainyo/alpaca-lora-7b\",\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "generation_config = GenerationConfig(\n",
    "    temperature=0.2,\n",
    "    top_p=0.75,\n",
    "    top_k=40,\n",
    "    num_beams=4,\n",
    "    max_new_tokens=128,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "if torch.__version__ >= \"2\":\n",
    "    model = torch.compile(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(instruction: str, input_ctxt: str = None) -> str:\n",
    "    if input_ctxt:\n",
    "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{input_ctxt}\n",
    "\n",
    "### Response:\"\"\"\n",
    "    else:\n",
    "        return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "\n",
    "instruction = \"What is the meaning of life?\"\n",
    "input_ctxt = None  # For some tasks, you can provide an input context to help the model generate a better response.\n",
    "\n",
    "prompt = generate_prompt(instruction, input_ctxt)\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "input_ids = input_ids.to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        generation_config=generation_config,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "    )\n",
    "\n",
    "response = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../data/finetune_train_val_test/train.csv')\n",
    "val_df = pd.read_csv('../../data/finetune_train_val_test/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = train_df.groupby('twitter user id').agg({\n",
    "    'texts': lambda x: ' [SEP] '.join(x),\n",
    "    'class': 'first',\n",
    "    'count_mention': 'first',\n",
    "    'count_link': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "grouped_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "examples_samples = grouped_df.groupby('class').apply(lambda x: x.sample(2, random_state=42)).sample(frac=1, random_state=11).reset_index(drop=True)\n",
    "examples_samples['formatted_string'] = examples_samples.apply(\n",
    "    lambda x: f\"Tweets: {x['texts']}\\nCategory: {x['class']}\\n\", axis=1\n",
    ")\n",
    "examples_prompt = ''.join(examples_samples['formatted_string'])\n",
    "prompt = f\"\"\"You are tasked to clasify Crypto Currency Twitter influencers into 5 categories: \"no influencer\",\"nano\",\"micro\",\"macro\",\"mega\" with \"no influencer\" being the user has no influence and \"mega\" the most influencing. To classify, you will analyze a list of Tweets by the users, separated by '[SEP]' and categorized them into 5 catgories.\\n{examples_prompt}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are tasked to clasify Crypto Currency Twitter influencers into 5 categories: \"no influencer\",\"nano\",\"micro\",\"macro\",\"mega\" with \"no influencer\" being the user has no influence and \"mega\" the most influencing. To classify, you will analyze a list of Tweets by the users, separated by \\'[SEP]\\' and categorized them into 5 catgories.\\nTweets: RT  1/ A ğŸ§µon how   currently works, why the FUD is wrong, and the real problems with the current protocol.Full disclâ€¦ [SEP] RT  I see no lies ğŸ˜‚ #LUNAtic $Luna #BTC #cryptocurrency http\\nCategory: nano\\nTweets: Requesting $MATIC funds from the #Stakely Faucet on the Polygon blockchain. Request ID: 2G65FUHU #privacy http [SEP] Requesting $MATIC funds from the #Stakely Faucet on the Polygon blockchain. Request ID: L1BAD0KX #privacy http\\nCategory: no influencer\\nTweets: RT  JUST IN: Canada formally labels the Proud Boys a terrorist entity. http [SEP] Happy Fathers Day to all you fathers out there. Love your family. Protect your family. Stay with your family. Forever. http [SEP] Happy birthday young man! Welcome to the #kissarmy. As soon as it is safe for you and all of us, we will see you soon! http [SEP] Shockingly and shamefully, Fox did not cover the funeral!!! http [SEP] Bring back Catherine Coley, say Iâ€¦..Binance Chief Brian Brooks Steps Down From Binance Just Months Into Tenure  http [SEP] RT  #ETH hits a new all-time high of $2,271 ğŸš€ [SEP] CNBC- Yes. Your boss can fire you if you refuse to take the vaccine! http [SEP] Debra, donâ€™t be jealous. It makes you look small. http [SEP] RT  THANK YOU to every member of the hard-working crew for helping us build the largest stage ever in the UAE. Whoâ€™s ready to #KISS20â€¦ [SEP] RT  Rep. Marjorie Taylor Greene mocked Parkland shooting survivor David Hogg in a 2019 interview with a Georgia gun group, a previâ€¦\\nCategory: mega\\nTweets: RT   hits 10 million TVL in under 96hrs from launch!ğŸš€ğŸš€Enjoy 0.02% swap fees on stablecoins and 11% daily on thâ€¦ [SEP] RT  ğŸŠ #SOLGiveaways ğŸŠğŸ: 1 x $sol     ( 45 $ )Rules:1âƒ£Follow  &amp;  &amp; â¤ï¸3ï¸âƒ£Tag friedsâ³48 Hâ€¦\\nCategory: nano\\nTweets: Hey Frens If your aren\\'t on http you are wrongğŸ¤ª is a platform where you can save on crypto, is that not wonderful ğŸ¤©ğŸ¤© thats not allDaily opportunity to Earn 5% APR in $BNB $EMP $NFTART $AMES    #Defi #Launch http [SEP] HOW TO MINT FCCYou have to have a $SOL wallet which can be either (Phantom, Sollet, Solflare etc) with a stipulated amount of $SOL required for mint, then go ahead to connect your wallet. âš ï¸BE CAREFUL WHEN CONNECTING MAKE SIRE YOU ARE ON THE RIGHT PLATFORMâš ï¸ http [SEP]  keeps breaking grounds on the crypto space and we arent ready to stop yetâœ¨$HEC and TOR goes live on  will also be going live soon, trust me it\\'s going to be explosive ğŸ¤¯#Bitmart #FTM $FTM #HECTORFINANCE #DEX $MIM $FRAX $USDC $USDT $DAI http [SEP] RT  Second Trailer ğŸ¤©!!! + 2000$ $TOR #GiveawayğŸ”¥HadesğŸ”¥Total in collection:  300xğŸ”¸150x CommonğŸ”¸75x UncommonğŸ”¸45x RareğŸ”¸24x Eâ€¦ [SEP] ğŸš¨NFT GIVEAWAY ALERTğŸš¨ and  are giving away amazing Arts of Zeus.ğŸ¤©ğŸ¤©You could be that lucky winner if you follow the instructions below on the quote tweetğŸ“ŒFollowâœ…  $HEC #FTM $FTM #NFT #NFTArts #Fantom #NFTcollection #NFTdrop http [SEP] Giveaway AlertğŸš¨10 WL Spots available for grab from  &amp;  ğŸ¤©These collections will be leading the way in the  on the Fantom Ecosystem âš¡ğŸ”—://t.co/4gnnaeV4rZ://t.co/OUJEVsEYhM $TOR #FTM #Fantom $FTM #NFTwhitelist #NFT http [SEP] RT  If you can\\'t handle red candles you are not ready to party the green candles $FTM [SEP] Hey FrensğŸ“¢Take part in this and make generational wealthâš¡âš¡Get on this and tag your pals on this, let\\'s all secure the bagğŸ’°Projects to look out for  $HEC #FTM $FTM #NFT #NFTcollection http [SEP] ğŸš¨GIVEAWAY ALERTğŸš¨If you have not joined the contest you are wrong.ğŸš«Be part of this and have the chance to win awesome pricesğŸ¤©ğŸ¤‘.Be early to  &amp;  NFTs community soon to the moonğŸš€ğŸš€#FTM $FTM #NFT #NFTDROP #NFTcollection #cryptocommunity http [SEP] RT  $TOR is here to stay, donâ€™t sleep on it! ğŸ‘‡$TOR - $FTM: 46.4% APY ğŸ”¥://t.co/osOp8bfUtjStable Curve Vault, $TOR, $USDC,â€¦\\nCategory: micro\\nTweets: Itâ€™s an open secret now that almost all #NFT marketplaces will soon support #Solana. So, what floors should I sweep with 1,000 $SOL? ğŸ‘‡ğŸ½ [SEP] Gm. Here\\'s the market ğŸ‘‡ğŸ¼/ $ETH no retracement, now at $3145 / OS trade vol up 15.5% past 24h (+$12M)/ Azuki vol surged +131%, floor now 19Î / Top collections holding, smaller projects seeing moderate liquidations / Expect liquidations to match $ETH breakout volatility [SEP] RT  Gm. Every interaction with this tweet enters to win $100 in $SOL ğŸ¤ [SEP] / Believe in what seems difficult Solana makes sense.I continue to believe, with some more work and patience, $SOL will become the preferred consumer chain. I could be wrong, but the case is strong.What else do you love about Solana? Have a great weekend friends â¤ï¸ [SEP] Great time to start DCA on $SOL. Upside is enormous in 2023 - 2025. [SEP] RT  Solana could dethrone $ETH before 2025. My thoughts;ğŸ§µ http [SEP] Some other notable L1s to consider Buying $NEAR now, +57% to prev ATHBuying $STX now, +103% to prev ATHBuying $KDA now, +310% to prev ATH [SEP] 8/8 This is just the beginning.I know there\\'s more to say, but this alone is enough to justify some exposure. Buy some $SOL. Get some #NFTs on  Watch what unfolds on Solana this year.Follow me for important news and alpha on $SOL this year:  â¤ï¸ [SEP] RT  Soâ€¦ Solana, somehow, with 12x less the market cap than $ETH&gt;Is doing more volume in NFT transactions than OpenSea&gt;Gâ€¦\\nCategory: micro\\nTweets: RT  Hon. Butiime: In order to give force to the Compensation Scheme, the Uganda\\nCategory: macro\\nTweets: \"mUh cHeAp fEeS\" narrative not working Roger? http [SEP] RT  You: \"I don\\'t understand why I would need money that is independent of world governments and corporations, hard to seize orâ€¦ [SEP] RT  Hard Forks hurt adoption, illustrated: http [SEP] RT  I\\'d be a *billionaire* now if I hadn\\'t sold the 55,000 bitcoins I mined on my laptop in 2009-2010 way too early (mostly beâ€¦ [SEP] RT  We are all Satoshi, except Craig Wright [SEP] RT  Digitally centralized assets are deeply unsafe. Don\\'t put so much of your family\\'s wealth in assets that some stranger canâ€¦ [SEP] RT  I think Bitcoin will 1000x in price over the next 50 years (in todayâ€™s USD purchasing power - all fiat is going to getâ€¦\\nCategory: mega\\nTweets:  I never look at this. Is it helpful? [SEP] All fed theories out the window now?://t.co/0PItGKaiEj [SEP] RT  man\\'s describing boobahub innit http [SEP]    1.2b fdv on 130m in tvl in a market with declining liquidity and market participants should prob be trading more around 3x vs 10x. [SEP] Iâ€™d like to think $ETH isnâ€™t going to 3 digits this week. [SEP]   It\\'s so manufactured I don\\'t believe a single thing China says in relation to Covid. [SEP] Ahh yes TVL. Which VC created it for you? [SEP]   Iâ€™m in the camp of squeeze and them eventually lose it. [SEP]  It could given how this mkt trades.\\nCategory: macro\\nTweets:  Great project that will revolutionarize the Cryptocurrency industry.    7vb3pDCggqHpqh5sfV9NX6druwXmssoLVbUrCk6zyug9$SOL #SolanaAirdrop #SEAS #Solana #Airdrop [SEP]  Great project that will revolutionarize the Cryptocurrency industry.   $CRYN $SOL #Airdrop #solana #SolanaAirdrop #memecoin [SEP]  Great project that will revolutionarize the Cryptocurrency industry.   $SINU #SolanaAirdrop #Airdrop $SAMO $Woof #SolanaSummer $SOL #Solana [SEP] #HappyFans  is launching soon! Get in on the action here: http #ETH $KCS $KCC #KCC $BNB $BTC $ADA $ETH      [SEP]  Great project that will revolutionarize the Cryptocurrency industry.   $SOL #Solana  #memecoin  #SolanaAirdrop #NFT #Airdrop #SAYMO #SAMO #dogecoin [SEP]  Great project that will revolutionarize the Cryptocurrency industry.7vb3pDCggqHpqh5sfV9NX6druwXmssoLVbUrCk6zyug9   #SolanaAirdrop #Atomsolana $SOL #Solana #Airdrop [SEP]  7vb3pDCggqHpqh5sfV9NX6druwXmssoLVbUrCk6zyug9Great project that will revolutionarize the Cryptocurrency industry.   $SQUID $SOL #Solana #SolanaAirdrop #Airdrop  #SQUID #Airdrops [SEP]  Great project that will revolutionarize the Cryptocurrency industry.   $SOL #SolanaAirdrop #KhabyLame #slp #meme #memetoken #Solana #Airdrop [SEP]  Great project that will revolutionarize the Cryptocurrency industry.  #Solana  #memecoin  #SolanaAirdrop #Airdrop $SFROG [SEP]  Great project that will revolutionarize the Cryptocurrency industry.   #SOL $SOL#memecoin #Airdrops\\nCategory: no influencer\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657c93fa9a274818982ef64dc38ab9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = OpenLlamaForCausalLM.from_pretrained('s-JoL/Open-Llama-V1')\n",
    "tokenizer = AutoTokenizer.from_pretrained('s-JoL/Open-Llama-V1')\n",
    "\n",
    "prompt = \"Hey, are you consciours? Can you talk to me?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=30)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = val_df.groupby('twitter user id').agg({\n",
    "    'texts': lambda x: ' [SEP] '.join(x),\n",
    "    'class': 'first',\n",
    "    'count_mention': 'first',\n",
    "    'count_link': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "grouped_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "val_examples = grouped_df.groupby('class').apply(lambda x: x.sample(5, random_state=42)).sample(frac=1, random_state=11).reset_index(drop=True)\n",
    "val_examples['formatted_string'] = val_examples.apply(\n",
    "    lambda x: f\"Tweets: {x['texts']}\\nCategory: {x['class']}\\n\", axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Tweets: Hey Frens If your aren't on http you are wrongğŸ¤ª is a platform where you can save on crypto, is that not wonderful ğŸ¤©ğŸ¤© thats not allDaily opportunity to Earn 5% APR in $BNB $EMP $NFTART $AMES    #Defi #Launch http [SEP] HOW TO MINT FCCYou have to have a $SOL wallet which can be either (Phantom, Sollet, Solflare etc) with a stipulated amount of $SOL required for mint, then go ahead to connect your wallet. âš ï¸BE CAREFUL WHEN CONNECTING MAKE SIRE YOU ARE ON THE RIGHT PLATFORMâš ï¸ http [SEP]  keeps breaking grounds on the crypto space and we arent ready to stop yetâœ¨$HEC and TOR goes live on  will also be going live soon, trust me it's going to be explosive ğŸ¤¯#Bitmart #FTM $FTM #HECTORFINANCE #DEX $MIM $FRAX $USDC $USDT $DAI http [SEP] RT  Second Trailer ğŸ¤©!!! + 2000$ $TOR #GiveawayğŸ”¥HadesğŸ”¥Total in collection:  300xğŸ”¸150x CommonğŸ”¸75x UncommonğŸ”¸45x RareğŸ”¸24x Eâ€¦ [SEP] ğŸš¨NFT GIVEAWAY ALERTğŸš¨ and  are giving away amazing Arts of Zeus.ğŸ¤©ğŸ¤©You could be that lucky winner if you follow the instructions below on the quote tweetğŸ“ŒFollowâœ…  $HEC #FTM $FTM #NFT #NFTArts #Fantom #NFTcollection #NFTdrop http [SEP] Giveaway AlertğŸš¨10 WL Spots available for grab from  &amp;  ğŸ¤©These collections will be leading the way in the  on the Fantom Ecosystem âš¡ğŸ”—://t.co/4gnnaeV4rZ://t.co/OUJEVsEYhM $TOR #FTM #Fantom $FTM #NFTwhitelist #NFT http [SEP] RT  If you can't handle red candles you are not ready to party the green candles $FTM [SEP] Hey FrensğŸ“¢Take part in this and make generational wealthâš¡âš¡Get on this and tag your pals on this, let's all secure the bagğŸ’°Projects to look out for  $HEC #FTM $FTM #NFT #NFTcollection http [SEP] ğŸš¨GIVEAWAY ALERTğŸš¨If you have not joined the contest you are wrong.ğŸš«Be part of this and have the chance to win awesome pricesğŸ¤©ğŸ¤‘.Be early to  &amp;  NFTs community soon to the moonğŸš€ğŸš€#FTM $FTM #NFT #NFTDROP #NFTcollection #cryptocommunity http [SEP] RT  $TOR is here to stay, donâ€™t sleep on it! ğŸ‘‡$TOR - $FTM: 46.4% APY ğŸ”¥://t.co/osOp8bfUtjStable Curve Vault, $TOR, $USDC,â€¦\\nCategory: micro\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_examples['formatted_string'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
