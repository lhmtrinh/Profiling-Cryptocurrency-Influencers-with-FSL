{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GenerationConfig, LlamaTokenizer, LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /mnt/home/lehoangminhtrinh/env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /mnt/home/lehoangminhtrinh/env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lehoangminhtrinh/env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda-10.1')}\n",
      "  warn(msg)\n",
      "/mnt/home/lehoangminhtrinh/env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/mnt/home/lehoangminhtrinh/env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/mnt/home/lehoangminhtrinh/env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer \u001b[39m=\u001b[39m LlamaTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mchainyo/alpaca-lora-7b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m LlamaForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mchainyo/alpaca-lora-7b\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     load_in_8bit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      5\u001b[0m     torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat16,\n\u001b[1;32m      6\u001b[0m     device_map\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m generation_config \u001b[39m=\u001b[39m GenerationConfig(\n\u001b[1;32m      9\u001b[0m     temperature\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[1;32m     10\u001b[0m     top_p\u001b[39m=\u001b[39m\u001b[39m0.75\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     max_new_tokens\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/env/lib/python3.8/site-packages/transformers/modeling_utils.py:2730\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2726\u001b[0m         device_map_without_lm_head \u001b[39m=\u001b[39m {\n\u001b[1;32m   2727\u001b[0m             key: device_map[key] \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m device_map\u001b[39m.\u001b[39mkeys() \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m modules_to_not_convert\n\u001b[1;32m   2728\u001b[0m         }\n\u001b[1;32m   2729\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m device_map_without_lm_head\u001b[39m.\u001b[39mvalues() \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdisk\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m device_map_without_lm_head\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m-> 2730\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2731\u001b[0m \u001b[39m                \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2732\u001b[0m \u001b[39m                Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\u001b[39;00m\n\u001b[1;32m   2733\u001b[0m \u001b[39m                the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\u001b[39;00m\n\u001b[1;32m   2734\u001b[0m \u001b[39m                these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\u001b[39;00m\n\u001b[1;32m   2735\u001b[0m \u001b[39m                `device_map` to `from_pretrained`. Check\u001b[39;00m\n\u001b[1;32m   2736\u001b[0m \u001b[39m                https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\u001b[39;00m\n\u001b[1;32m   2737\u001b[0m \u001b[39m                for more details.\u001b[39;00m\n\u001b[1;32m   2738\u001b[0m \u001b[39m                \"\"\"\u001b[39;00m\n\u001b[1;32m   2739\u001b[0m             )\n\u001b[1;32m   2740\u001b[0m         \u001b[39mdel\u001b[39;00m device_map_without_lm_head\n\u001b[1;32m   2742\u001b[0m \u001b[39mif\u001b[39;00m from_tf:\n",
      "\u001b[0;31mValueError\u001b[0m: \n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        "
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\"chainyo/alpaca-lora-7b\")\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    \"chainyo/alpaca-lora-7b\",\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "generation_config = GenerationConfig(\n",
    "    temperature=0.2,\n",
    "    top_p=0.75,\n",
    "    top_k=40,\n",
    "    num_beams=4,\n",
    "    max_new_tokens=128,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "if torch.__version__ >= \"2\":\n",
    "    model = torch.compile(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(instruction: str, input_ctxt: str = None) -> str:\n",
    "    if input_ctxt:\n",
    "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{input_ctxt}\n",
    "\n",
    "### Response:\"\"\"\n",
    "    else:\n",
    "        return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "\n",
    "instruction = \"What is the meaning of life?\"\n",
    "input_ctxt = None  # For some tasks, you can provide an input context to help the model generate a better response.\n",
    "\n",
    "prompt = generate_prompt(instruction, input_ctxt)\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "input_ids = input_ids.to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        generation_config=generation_config,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "    )\n",
    "\n",
    "response = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../data/finetune_train_val_test/train.csv')\n",
    "val_df = pd.read_csv('../../data/finetune_train_val_test/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = train_df.groupby('twitter user id').agg({\n",
    "    'texts': lambda x: ' [SEP] '.join(x),\n",
    "    'class': 'first',\n",
    "    'count_mention': 'first',\n",
    "    'count_link': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "grouped_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "examples_samples = grouped_df.groupby('class').apply(lambda x: x.sample(2, random_state=42)).sample(frac=1, random_state=11).reset_index(drop=True)\n",
    "examples_samples['formatted_string'] = examples_samples.apply(\n",
    "    lambda x: f\"Tweets: {x['texts']}\\nCategory: {x['class']}\\n\", axis=1\n",
    ")\n",
    "examples_prompt = ''.join(examples_samples['formatted_string'])\n",
    "prompt = f\"\"\"You are tasked to clasify Crypto Currency Twitter influencers into 5 categories: \"no influencer\",\"nano\",\"micro\",\"macro\",\"mega\" with \"no influencer\" being the user has no influence and \"mega\" the most influencing. To classify, you will analyze a list of Tweets by the users, separated by '[SEP]' and categorized them into 5 catgories.\\n{examples_prompt}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are tasked to clasify Crypto Currency Twitter influencers into 5 categories: \"no influencer\",\"nano\",\"micro\",\"macro\",\"mega\" with \"no influencer\" being the user has no influence and \"mega\" the most influencing. To classify, you will analyze a list of Tweets by the users, separated by \\'[SEP]\\' and categorized them into 5 catgories.\\nTweets: RT  1/ A 🧵on how   currently works, why the FUD is wrong, and the real problems with the current protocol.Full discl… [SEP] RT  I see no lies 😂 #LUNAtic $Luna #BTC #cryptocurrency http\\nCategory: nano\\nTweets: Requesting $MATIC funds from the #Stakely Faucet on the Polygon blockchain. Request ID: 2G65FUHU #privacy http [SEP] Requesting $MATIC funds from the #Stakely Faucet on the Polygon blockchain. Request ID: L1BAD0KX #privacy http\\nCategory: no influencer\\nTweets: RT  JUST IN: Canada formally labels the Proud Boys a terrorist entity. http [SEP] Happy Fathers Day to all you fathers out there. Love your family. Protect your family. Stay with your family. Forever. http [SEP] Happy birthday young man! Welcome to the #kissarmy. As soon as it is safe for you and all of us, we will see you soon! http [SEP] Shockingly and shamefully, Fox did not cover the funeral!!! http [SEP] Bring back Catherine Coley, say I…..Binance Chief Brian Brooks Steps Down From Binance Just Months Into Tenure  http [SEP] RT  #ETH hits a new all-time high of $2,271 🚀 [SEP] CNBC- Yes. Your boss can fire you if you refuse to take the vaccine! http [SEP] Debra, don’t be jealous. It makes you look small. http [SEP] RT  THANK YOU to every member of the hard-working crew for helping us build the largest stage ever in the UAE. Who’s ready to #KISS20… [SEP] RT  Rep. Marjorie Taylor Greene mocked Parkland shooting survivor David Hogg in a 2019 interview with a Georgia gun group, a previ…\\nCategory: mega\\nTweets: RT   hits 10 million TVL in under 96hrs from launch!🚀🚀Enjoy 0.02% swap fees on stablecoins and 11% daily on th… [SEP] RT  🎊 #SOLGiveaways 🎊🎁: 1 x $sol     ( 45 $ )Rules:1⃣Follow  &amp;  &amp; ❤️3️⃣Tag frieds⏳48 H…\\nCategory: nano\\nTweets: Hey Frens If your aren\\'t on http you are wrong🤪 is a platform where you can save on crypto, is that not wonderful 🤩🤩 thats not allDaily opportunity to Earn 5% APR in $BNB $EMP $NFTART $AMES    #Defi #Launch http [SEP] HOW TO MINT FCCYou have to have a $SOL wallet which can be either (Phantom, Sollet, Solflare etc) with a stipulated amount of $SOL required for mint, then go ahead to connect your wallet. ⚠️BE CAREFUL WHEN CONNECTING MAKE SIRE YOU ARE ON THE RIGHT PLATFORM⚠️ http [SEP]  keeps breaking grounds on the crypto space and we arent ready to stop yet✨$HEC and TOR goes live on  will also be going live soon, trust me it\\'s going to be explosive 🤯#Bitmart #FTM $FTM #HECTORFINANCE #DEX $MIM $FRAX $USDC $USDT $DAI http [SEP] RT  Second Trailer 🤩!!! + 2000$ $TOR #Giveaway🔥Hades🔥Total in collection:  300x🔸150x Common🔸75x Uncommon🔸45x Rare🔸24x E… [SEP] 🚨NFT GIVEAWAY ALERT🚨 and  are giving away amazing Arts of Zeus.🤩🤩You could be that lucky winner if you follow the instructions below on the quote tweet📌Follow✅  $HEC #FTM $FTM #NFT #NFTArts #Fantom #NFTcollection #NFTdrop http [SEP] Giveaway Alert🚨10 WL Spots available for grab from  &amp;  🤩These collections will be leading the way in the  on the Fantom Ecosystem ⚡🔗://t.co/4gnnaeV4rZ://t.co/OUJEVsEYhM $TOR #FTM #Fantom $FTM #NFTwhitelist #NFT http [SEP] RT  If you can\\'t handle red candles you are not ready to party the green candles $FTM [SEP] Hey Frens📢Take part in this and make generational wealth⚡⚡Get on this and tag your pals on this, let\\'s all secure the bag💰Projects to look out for  $HEC #FTM $FTM #NFT #NFTcollection http [SEP] 🚨GIVEAWAY ALERT🚨If you have not joined the contest you are wrong.🚫Be part of this and have the chance to win awesome prices🤩🤑.Be early to  &amp;  NFTs community soon to the moon🚀🚀#FTM $FTM #NFT #NFTDROP #NFTcollection #cryptocommunity http [SEP] RT  $TOR is here to stay, don’t sleep on it! 👇$TOR - $FTM: 46.4% APY 🔥://t.co/osOp8bfUtjStable Curve Vault, $TOR, $USDC,…\\nCategory: micro\\nTweets: It’s an open secret now that almost all #NFT marketplaces will soon support #Solana. So, what floors should I sweep with 1,000 $SOL? 👇🏽 [SEP] Gm. Here\\'s the market 👇🏼/ $ETH no retracement, now at $3145 / OS trade vol up 15.5% past 24h (+$12M)/ Azuki vol surged +131%, floor now 19Ξ / Top collections holding, smaller projects seeing moderate liquidations / Expect liquidations to match $ETH breakout volatility [SEP] RT  Gm. Every interaction with this tweet enters to win $100 in $SOL 🤝 [SEP] / Believe in what seems difficult Solana makes sense.I continue to believe, with some more work and patience, $SOL will become the preferred consumer chain. I could be wrong, but the case is strong.What else do you love about Solana? Have a great weekend friends ❤️ [SEP] Great time to start DCA on $SOL. Upside is enormous in 2023 - 2025. [SEP] RT  Solana could dethrone $ETH before 2025. My thoughts;🧵 http [SEP] Some other notable L1s to consider Buying $NEAR now, +57% to prev ATHBuying $STX now, +103% to prev ATHBuying $KDA now, +310% to prev ATH [SEP] 8/8 This is just the beginning.I know there\\'s more to say, but this alone is enough to justify some exposure. Buy some $SOL. Get some #NFTs on  Watch what unfolds on Solana this year.Follow me for important news and alpha on $SOL this year:  ❤️ [SEP] RT  So… Solana, somehow, with 12x less the market cap than $ETH&gt;Is doing more volume in NFT transactions than OpenSea&gt;G…\\nCategory: micro\\nTweets: RT  Hon. Butiime: In order to give force to the Compensation Scheme, the Uganda\\nCategory: macro\\nTweets: \"mUh cHeAp fEeS\" narrative not working Roger? http [SEP] RT  You: \"I don\\'t understand why I would need money that is independent of world governments and corporations, hard to seize or… [SEP] RT  Hard Forks hurt adoption, illustrated: http [SEP] RT  I\\'d be a *billionaire* now if I hadn\\'t sold the 55,000 bitcoins I mined on my laptop in 2009-2010 way too early (mostly be… [SEP] RT  We are all Satoshi, except Craig Wright [SEP] RT  Digitally centralized assets are deeply unsafe. Don\\'t put so much of your family\\'s wealth in assets that some stranger can… [SEP] RT  I think Bitcoin will 1000x in price over the next 50 years (in today’s USD purchasing power - all fiat is going to get…\\nCategory: mega\\nTweets:  I never look at this. Is it helpful? [SEP] All fed theories out the window now?://t.co/0PItGKaiEj [SEP] RT  man\\'s describing boobahub innit http [SEP]    1.2b fdv on 130m in tvl in a market with declining liquidity and market participants should prob be trading more around 3x vs 10x. [SEP] I’d like to think $ETH isn’t going to 3 digits this week. [SEP]   It\\'s so manufactured I don\\'t believe a single thing China says in relation to Covid. [SEP] Ahh yes TVL. Which VC created it for you? [SEP]   I’m in the camp of squeeze and them eventually lose it. [SEP]  It could given how this mkt trades.\\nCategory: macro\\nTweets:  Great project that will revolutionarize the Cryptocurrency industry.    7vb3pDCggqHpqh5sfV9NX6druwXmssoLVbUrCk6zyug9$SOL #SolanaAirdrop #SEAS #Solana #Airdrop [SEP]  Great project that will revolutionarize the Cryptocurrency industry.   $CRYN $SOL #Airdrop #solana #SolanaAirdrop #memecoin [SEP]  Great project that will revolutionarize the Cryptocurrency industry.   $SINU #SolanaAirdrop #Airdrop $SAMO $Woof #SolanaSummer $SOL #Solana [SEP] #HappyFans  is launching soon! Get in on the action here: http #ETH $KCS $KCC #KCC $BNB $BTC $ADA $ETH      [SEP]  Great project that will revolutionarize the Cryptocurrency industry.   $SOL #Solana  #memecoin  #SolanaAirdrop #NFT #Airdrop #SAYMO #SAMO #dogecoin [SEP]  Great project that will revolutionarize the Cryptocurrency industry.7vb3pDCggqHpqh5sfV9NX6druwXmssoLVbUrCk6zyug9   #SolanaAirdrop #Atomsolana $SOL #Solana #Airdrop [SEP]  7vb3pDCggqHpqh5sfV9NX6druwXmssoLVbUrCk6zyug9Great project that will revolutionarize the Cryptocurrency industry.   $SQUID $SOL #Solana #SolanaAirdrop #Airdrop  #SQUID #Airdrops [SEP]  Great project that will revolutionarize the Cryptocurrency industry.   $SOL #SolanaAirdrop #KhabyLame #slp #meme #memetoken #Solana #Airdrop [SEP]  Great project that will revolutionarize the Cryptocurrency industry.  #Solana  #memecoin  #SolanaAirdrop #Airdrop $SFROG [SEP]  Great project that will revolutionarize the Cryptocurrency industry.   #SOL $SOL#memecoin #Airdrops\\nCategory: no influencer\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657c93fa9a274818982ef64dc38ab9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = OpenLlamaForCausalLM.from_pretrained('s-JoL/Open-Llama-V1')\n",
    "tokenizer = AutoTokenizer.from_pretrained('s-JoL/Open-Llama-V1')\n",
    "\n",
    "prompt = \"Hey, are you consciours? Can you talk to me?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=30)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = val_df.groupby('twitter user id').agg({\n",
    "    'texts': lambda x: ' [SEP] '.join(x),\n",
    "    'class': 'first',\n",
    "    'count_mention': 'first',\n",
    "    'count_link': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "grouped_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "val_examples = grouped_df.groupby('class').apply(lambda x: x.sample(5, random_state=42)).sample(frac=1, random_state=11).reset_index(drop=True)\n",
    "val_examples['formatted_string'] = val_examples.apply(\n",
    "    lambda x: f\"Tweets: {x['texts']}\\nCategory: {x['class']}\\n\", axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Tweets: Hey Frens If your aren't on http you are wrong🤪 is a platform where you can save on crypto, is that not wonderful 🤩🤩 thats not allDaily opportunity to Earn 5% APR in $BNB $EMP $NFTART $AMES    #Defi #Launch http [SEP] HOW TO MINT FCCYou have to have a $SOL wallet which can be either (Phantom, Sollet, Solflare etc) with a stipulated amount of $SOL required for mint, then go ahead to connect your wallet. ⚠️BE CAREFUL WHEN CONNECTING MAKE SIRE YOU ARE ON THE RIGHT PLATFORM⚠️ http [SEP]  keeps breaking grounds on the crypto space and we arent ready to stop yet✨$HEC and TOR goes live on  will also be going live soon, trust me it's going to be explosive 🤯#Bitmart #FTM $FTM #HECTORFINANCE #DEX $MIM $FRAX $USDC $USDT $DAI http [SEP] RT  Second Trailer 🤩!!! + 2000$ $TOR #Giveaway🔥Hades🔥Total in collection:  300x🔸150x Common🔸75x Uncommon🔸45x Rare🔸24x E… [SEP] 🚨NFT GIVEAWAY ALERT🚨 and  are giving away amazing Arts of Zeus.🤩🤩You could be that lucky winner if you follow the instructions below on the quote tweet📌Follow✅  $HEC #FTM $FTM #NFT #NFTArts #Fantom #NFTcollection #NFTdrop http [SEP] Giveaway Alert🚨10 WL Spots available for grab from  &amp;  🤩These collections will be leading the way in the  on the Fantom Ecosystem ⚡🔗://t.co/4gnnaeV4rZ://t.co/OUJEVsEYhM $TOR #FTM #Fantom $FTM #NFTwhitelist #NFT http [SEP] RT  If you can't handle red candles you are not ready to party the green candles $FTM [SEP] Hey Frens📢Take part in this and make generational wealth⚡⚡Get on this and tag your pals on this, let's all secure the bag💰Projects to look out for  $HEC #FTM $FTM #NFT #NFTcollection http [SEP] 🚨GIVEAWAY ALERT🚨If you have not joined the contest you are wrong.🚫Be part of this and have the chance to win awesome prices🤩🤑.Be early to  &amp;  NFTs community soon to the moon🚀🚀#FTM $FTM #NFT #NFTDROP #NFTcollection #cryptocommunity http [SEP] RT  $TOR is here to stay, don’t sleep on it! 👇$TOR - $FTM: 46.4% APY 🔥://t.co/osOp8bfUtjStable Curve Vault, $TOR, $USDC,…\\nCategory: micro\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_examples['formatted_string'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
