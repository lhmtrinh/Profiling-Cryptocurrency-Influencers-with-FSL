{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lhmtr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lhmtr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# Download the stopwords from NLTK\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge text and label df\n",
    "text_df = pd.read_json(\"raw_data/train_text.json\",lines=True)\n",
    "label_df = pd.read_json(\"raw_data/train_truth.json\", lines=True)\n",
    "\n",
    "df = pd.merge(text_df,label_df, on='twitter user id').drop(columns = ['tweet ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the dataframe\n",
    "expanded_rows = []\n",
    "for index, row in df.iterrows():\n",
    "    for text_dict in row['texts']:\n",
    "        new_row = row.copy()\n",
    "        new_row['texts'] = text_dict['text']\n",
    "        expanded_rows.append(new_row)\n",
    "\n",
    "df = pd.DataFrame(expanded_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    # Translate emojis to words\n",
    "    tweet = emoji.demojize(tweet)\n",
    "\n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove user mentions and count them\n",
    "    mentions = re.findall(r'@\\w+', tweet)\n",
    "    count_mentions = len(mentions)\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)\n",
    "\n",
    "    # Remove special characters and numbers\n",
    "    tweet = re.sub(r'\\W', ' ', tweet)\n",
    "\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = word_tokenize(tweet)\n",
    "    tokens = [word.lower() for word in tokens if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "    # Join the words back into a single string\n",
    "    tweet = ' '.join(tokens)\n",
    "\n",
    "    return tweet, count_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing function to the 'tweet' column\n",
    "df['texts'], df['count_mention'] = zip(*df['texts'].apply(preprocess_tweet))\n",
    "\n",
    "# Remove duplicate tweets based on the 'tweet_processed' column\n",
    "df = df.drop_duplicates(subset=['texts'])\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "# Count the number of words in each row of the specified column\n",
    "df['word_count'] = df['texts'].apply(count_words)\n",
    "\n",
    "# Remove rows with less than 5 words in the specified column\n",
    "df = df[df['word_count'] >= 5]\n",
    "\n",
    "# Drop the 'word_count' column as it's no longer needed\n",
    "df = df.drop(columns=['word_count'])\n",
    "\n",
    "# Save the preprocessed DataFrame to a new CSV file\n",
    "df.to_csv('data/preprocessed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitter user id</th>\n",
       "      <th>texts</th>\n",
       "      <th>class</th>\n",
       "      <th>count_mention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0037a672f0ed64b3231bac64853a278d</td>\n",
       "      <td>rt ape ape give apes tweeting great pics atamc...</td>\n",
       "      <td>nano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0037a672f0ed64b3231bac64853a278d</td>\n",
       "      <td>see single valid reason sell ape</td>\n",
       "      <td>nano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03eaa72711143b521c073d9ac5745923</td>\n",
       "      <td>rt need knock heels together three times say s...</td>\n",
       "      <td>nano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03eaa72711143b521c073d9ac5745923</td>\n",
       "      <td>index_pointing_up would love input tezos clean...</td>\n",
       "      <td>nano</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03eaa72711143b521c073d9ac5745923</td>\n",
       "      <td>rt fresh drop purple_heart 3 men please merrie...</td>\n",
       "      <td>nano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>fec182516cba4b665e2215094bbcc527</td>\n",
       "      <td>rt ok giving away 0 5 sol 5 discord invites rt...</td>\n",
       "      <td>nano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>fec182516cba4b665e2215094bbcc527</td>\n",
       "      <td>rt sol vs eth sol handshake eth</td>\n",
       "      <td>nano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>fec182516cba4b665e2215094bbcc527</td>\n",
       "      <td>rt wrapped_gift vanguards x yaku corp wrapped_...</td>\n",
       "      <td>nano</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>fec182516cba4b665e2215094bbcc527</td>\n",
       "      <td>rt giving away y00ts t00b nft crystal_ball flo...</td>\n",
       "      <td>nano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>fec182516cba4b665e2215094bbcc527</td>\n",
       "      <td>rt police_car_light silent solohs wl nftgiveaw...</td>\n",
       "      <td>nano</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>791 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      twitter user id  \\\n",
       "0    0037a672f0ed64b3231bac64853a278d   \n",
       "0    0037a672f0ed64b3231bac64853a278d   \n",
       "1    03eaa72711143b521c073d9ac5745923   \n",
       "1    03eaa72711143b521c073d9ac5745923   \n",
       "1    03eaa72711143b521c073d9ac5745923   \n",
       "..                                ...   \n",
       "159  fec182516cba4b665e2215094bbcc527   \n",
       "159  fec182516cba4b665e2215094bbcc527   \n",
       "159  fec182516cba4b665e2215094bbcc527   \n",
       "159  fec182516cba4b665e2215094bbcc527   \n",
       "159  fec182516cba4b665e2215094bbcc527   \n",
       "\n",
       "                                                 texts class  count_mention  \n",
       "0    rt ape ape give apes tweeting great pics atamc...  nano              1  \n",
       "0                     see single valid reason sell ape  nano              1  \n",
       "1    rt need knock heels together three times say s...  nano              1  \n",
       "1    index_pointing_up would love input tezos clean...  nano              0  \n",
       "1    rt fresh drop purple_heart 3 men please merrie...  nano              1  \n",
       "..                                                 ...   ...            ...  \n",
       "159  rt ok giving away 0 5 sol 5 discord invites rt...  nano              1  \n",
       "159                    rt sol vs eth sol handshake eth  nano              1  \n",
       "159  rt wrapped_gift vanguards x yaku corp wrapped_...  nano              2  \n",
       "159  rt giving away y00ts t00b nft crystal_ball flo...  nano              1  \n",
       "159  rt police_car_light silent solohs wl nftgiveaw...  nano              2  \n",
       "\n",
       "[791 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
